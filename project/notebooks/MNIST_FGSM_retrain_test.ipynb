{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named util",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c19d815efb39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named util"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import util\n",
    "import model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import itertools as itr\n",
    "from scipy.misc import imread\n",
    "from PIL import Image\n",
    "from random import randrange\n",
    "from collections import Counter\n",
    "\n",
    "#cleverhans\n",
    "from cleverhans.utils_mnist import data_mnist\n",
    "from cleverhans.utils_tf import model_train, model_eval\n",
    "from cleverhans.utils import AccuracyReport\n",
    "from cleverhans.utils_keras import cnn_model, KerasModelWrapper\n",
    "from cleverhans.utils_keras import KerasModelWrapper\n",
    "from cleverhans.attacks import FastGradientMethod, LBFGS, BasicIterativeMethod\n",
    "from cleverhans.utils import AccuracyReport\n",
    "\n",
    "#keras\n",
    "import keras\n",
    "from keras import __version__\n",
    "from keras import backend as K\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import mnist\n",
    "print(\"Finished Import\")\n",
    "\n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_string('data_dir', '', 'directory where MNIST is located')\n",
    "flags.DEFINE_string('save_dir', '', 'directory where model graph and weights are saved')\n",
    "flags.DEFINE_integer('batch_size', 128, '')\n",
    "flags.DEFINE_float('lr', 0.001, '')\n",
    "flags.DEFINE_integer('early_stop', 20, '')\n",
    "flags.DEFINE_string('db', 'emodb', '')\n",
    "flags.DEFINE_integer('epochs', 10, '')\n",
    "flags.DEFINE_float('reg_coeff', 0.001, '')\n",
    "flags.DEFINE_float('split', 0.90, '')\n",
    "flags.DEFINE_string('master', '', 'The address of the TensorFlow master to use.')\n",
    "flags.DEFINE_string('checkpoint_path', 'nips-2017-adversarial-learning-development-set/inception_v3.ckpt', 'Path to checkpoint for inception network.')\n",
    "flags.DEFINE_string('input_dir', 'nips-2017-adversarial-learning-development-set/images/', 'Input directory with images.')\n",
    "flags.DEFINE_string('output_dir', '', 'Output directory with images.')\n",
    "flags.DEFINE_float('max_epsilon', 4.0, 'Maximum size of adversarial perturbation.')\n",
    "flags.DEFINE_integer('image_width', 28, 'Width of each input images.')\n",
    "flags.DEFINE_integer('image_height', 28, 'Height of each input images.')\n",
    "flags.DEFINE_float('eps', 2.0 * 16.0 / 255.0, '')\n",
    "flags.DEFINE_integer('num_classes', 10, '')\n",
    "flags.DEFINE_integer('num_ens', 10, '')\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "# Set arguments:  Save_Dir Structure Learning_Rate Earling_Stoping Batch_Size Data_Dir    \n",
    "epochs = FLAGS.epochs\n",
    "data_dir = FLAGS.data_dir\n",
    "save_dir = FLAGS.save_dir\n",
    "learning_rate = FLAGS.lr\n",
    "early_stop = FLAGS.early_stop\n",
    "batch_size = FLAGS.batch_size\n",
    "reg_coeff = FLAGS.reg_coeff\n",
    "split = FLAGS.split\n",
    "master = FLAGS.master\n",
    "checkpoint_path = FLAGS.checkpoint_path\n",
    "input_dir = FLAGS.input_dir\n",
    "output_dir = FLAGS.output_dir\n",
    "image_width = FLAGS.image_width\n",
    "image_height = FLAGS.image_height\n",
    "num_classes = FLAGS.num_classes\n",
    "eps = FLAGS.eps\n",
    "batch_shape = [batch_size, image_height, image_width, 3]\n",
    "num_ens = FLAGS.num_ens\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, image_width, image_height)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, image_width, image_height)\n",
    "    input_shape = (1, image_width, image_height)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], image_width, image_height, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], image_width, image_height, 1)\n",
    "    input_shape = (image_width, image_height, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "#Our model architecture for MNIST dataset\n",
    "def model_arch():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                optimizer=keras.optimizers.Adadelta(),\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "sess = tf.Session()\n",
    "keras.backend.set_session(sess)\n",
    "\n",
    "x_noisy = util.add_gaussian_noise(x_train,0,64) #Add gaussian noise to all images\n",
    "preds_ens = np.zeros((x_test.shape[0],10)) #variable to store the predictions of each model in the ensemble (10)\n",
    "max_vote_ens = np.zeros(x_test.shape[0])  #variable to store Majority vote from all models in ensemble\n",
    "\n",
    "\n",
    "#-----------------------------------Adversarial Training--------------------------------------------------------------\n",
    "#first adversarial examples are generated using train_data, then the model is trained on train_data+adv_train_data.\n",
    "#Then the model is tested on normal test_data, then the model is tested on adversarial_test_data.\n",
    "#So, we are generating the adversarial examples twice both on train and test data.\n",
    "\n",
    "model = load_model(\"models/fgsm_model.h5\")\n",
    "wrap = KerasModelWrapper(model)\n",
    "\n",
    "#generate adversarial examples on train data.\n",
    "adv_fgsm_train = util.fgsm_attack(x_train,model,sess)\n",
    "adv_bim_train = util.bim_attack(x_train,model,sess)\n",
    "adv_lbfgs_train = util.lbfgs_attack(x_train,model,sess,6)\n",
    "train_plus_adv_fgsm = np.concatenate([x_train,adv_fgsm_train])\n",
    "y_train_plus_adv_fgsm = np.concatenate([y_train,y_train])\n",
    "train_plus_adv_bim = np.concatenate([x_train,adv_bim_train])\n",
    "y_train_plus_adv_bim = np.concatenate([y_train,y_train])\n",
    "train_plus_adv_lbfgs = np.concatenate([x_train,adv_lbfgs_train])\n",
    "y_train_plus_adv_lbfgs = np.concatenate([y_train,y_train])\n",
    "\n",
    "#FGSM TRAINING\n",
    "#build a fresh model for fgsm training\n",
    "fgsm_acc_train = model.evaluate(x_test,y_test,verbose=0)\n",
    "fgsm_acc_train[1] #Accuracy of adversarially trained model on clean examples\n",
    "\n",
    "#generate adversarial examples for adversarially trained model on test_data\n",
    "adv_fgsm_test = util.fgsm_attack(x_test,model,sess)\n",
    "fgsm_adv_acc_train = model.evaluate(adv_fgsm_test,y_test,verbose=0)\n",
    "fgsm_adv_acc_train[1] #Accuracy of adversarially trained model on adv_test images\n",
    "\n",
    "#BIM TESTING\n",
    "#generate adversarial examples for adversarially trained model on test_data\n",
    "adv_bim_test = util.bim_attack(x_test,model,sess)\n",
    "bim_adv_acc_train = model.evaluate(adv_bim_test,y_test,verbose=0)\n",
    "bim_adv_acc_train[1] #Accuracy of adversarially trained model on adv_test images\n",
    "\n",
    "#LBFGS TESTING\n",
    "#generate adversarial examples for adversarially trained model on test_data\n",
    "adv_lbfgs_test = util.lbfgs_attack(x_test,model,sess,6)\n",
    "lbfgs_adv_acc_train = model.evaluate(adv_lbfgs_test,y_test,verbose=0)\n",
    "lbfgs_adv_acc_train[1] #Accuracy of adversarially trained model on adv_test images\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
